{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"44011120ae5442d9a43689af71b87f9e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e49dadef281941488c426e5c4626ed13","IPY_MODEL_eb2a8b544d5c41eea2db1b2a56e88d33","IPY_MODEL_b6af843580634335bf0ebdfc6a9baf62"],"layout":"IPY_MODEL_6c785cef0fb249a69ea6b30815b23a55"}},"e49dadef281941488c426e5c4626ed13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9e4d38e7bf6427893a606ea64d6295b","placeholder":"​","style":"IPY_MODEL_66dbcfde174149268bf7c8a3124a87e3","value":"tokenizer_config.json: 100%"}},"eb2a8b544d5c41eea2db1b2a56e88d33":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c36128f963d4e6e9ec05fa77c6193d5","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8204ff0390284060ad7892d92f56565a","value":48}},"b6af843580634335bf0ebdfc6a9baf62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6a76cdca4a544d5919f5bba09aa6345","placeholder":"​","style":"IPY_MODEL_ad97067e92474e56abd5708b521d6d88","value":" 48.0/48.0 [00:00&lt;00:00, 604B/s]"}},"6c785cef0fb249a69ea6b30815b23a55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9e4d38e7bf6427893a606ea64d6295b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66dbcfde174149268bf7c8a3124a87e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c36128f963d4e6e9ec05fa77c6193d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8204ff0390284060ad7892d92f56565a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a6a76cdca4a544d5919f5bba09aa6345":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad97067e92474e56abd5708b521d6d88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00110d9a1a704460a1a9fde626b89275":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb75fc3d2a6a4cbab0faa6f934b74379","IPY_MODEL_8261f7d145e34a6aaffc2eb1ba083afc","IPY_MODEL_6e2b00787160478d868e32c4928aba1b"],"layout":"IPY_MODEL_c77bfcd35a6f422482eba59bb7e8273c"}},"bb75fc3d2a6a4cbab0faa6f934b74379":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a711e963016a46c2b2b62fd19a13dc30","placeholder":"​","style":"IPY_MODEL_338c81578b6c496d940d9e61c75bdbe0","value":"vocab.txt: 100%"}},"8261f7d145e34a6aaffc2eb1ba083afc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e79496069854401ba5c879b2ab52388","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a399a7f948ed47d6ae2b68d593f2810d","value":231508}},"6e2b00787160478d868e32c4928aba1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d55bdb4b5e54cba97d6946c80b2c7f7","placeholder":"​","style":"IPY_MODEL_9587349a72c64e4189308080881d6e1b","value":" 232k/232k [00:00&lt;00:00, 1.49MB/s]"}},"c77bfcd35a6f422482eba59bb7e8273c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a711e963016a46c2b2b62fd19a13dc30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"338c81578b6c496d940d9e61c75bdbe0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e79496069854401ba5c879b2ab52388":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a399a7f948ed47d6ae2b68d593f2810d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d55bdb4b5e54cba97d6946c80b2c7f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9587349a72c64e4189308080881d6e1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"518e0780b65b4f6696d060aae15f78b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31dd4d411d994276b579792c3cbd7028","IPY_MODEL_9fa4a30645b84183a5d0c81030e9b437","IPY_MODEL_5efe421d3b33487d91b19dcc474c09fc"],"layout":"IPY_MODEL_1496a4e2d81e462d8a6ebc6eea4b34b1"}},"31dd4d411d994276b579792c3cbd7028":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e818d0c6415424facd7f99772c5e9b2","placeholder":"​","style":"IPY_MODEL_d292bef3784849a797b3a158549032c3","value":"tokenizer.json: 100%"}},"9fa4a30645b84183a5d0c81030e9b437":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0af1c62eea854dcd95e74ac124b43a32","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cfd2dd273a564c70b5a228b955d9add3","value":466062}},"5efe421d3b33487d91b19dcc474c09fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40f2646b2b074bd2821492ecbb9a4115","placeholder":"​","style":"IPY_MODEL_1662d3e065b44a56a8f29cd615b9e419","value":" 466k/466k [00:00&lt;00:00, 2.96MB/s]"}},"1496a4e2d81e462d8a6ebc6eea4b34b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e818d0c6415424facd7f99772c5e9b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d292bef3784849a797b3a158549032c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0af1c62eea854dcd95e74ac124b43a32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfd2dd273a564c70b5a228b955d9add3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"40f2646b2b074bd2821492ecbb9a4115":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1662d3e065b44a56a8f29cd615b9e419":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"064fa52e7d98449996f64c79398ae065":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb2b4d56562b45dcb6c5e31072b6dbe7","IPY_MODEL_afff58cb478b4a93a56d840a5ad95481","IPY_MODEL_c25e27d1d15e49cc8a109462034547a6"],"layout":"IPY_MODEL_255b3ad2d71948fb97c071dfcc72750a"}},"bb2b4d56562b45dcb6c5e31072b6dbe7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5d34f2d640f48fc8848d63821d11a18","placeholder":"​","style":"IPY_MODEL_2ed8ab2aff414b41b3bd75e8cbde1850","value":"config.json: 100%"}},"afff58cb478b4a93a56d840a5ad95481":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ae39ec1fa014d16b45648124ba8ea47","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f3408a63bd54e72be913566a1458d8a","value":570}},"c25e27d1d15e49cc8a109462034547a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86c526b18dc94b62a1fed8bbf0ef828b","placeholder":"​","style":"IPY_MODEL_60124a541126438ba65fe80275037ba9","value":" 570/570 [00:00&lt;00:00, 7.26kB/s]"}},"255b3ad2d71948fb97c071dfcc72750a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5d34f2d640f48fc8848d63821d11a18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ed8ab2aff414b41b3bd75e8cbde1850":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ae39ec1fa014d16b45648124ba8ea47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f3408a63bd54e72be913566a1458d8a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"86c526b18dc94b62a1fed8bbf0ef828b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60124a541126438ba65fe80275037ba9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7c2756e2b6746cf95f2278a7b982681":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a5551339b9c4b6685cabe1f4bb8d761","IPY_MODEL_52a6d6de75b14ee794da273704e0201b","IPY_MODEL_6b09ed1c3d0444af98f856d530dd49da"],"layout":"IPY_MODEL_80ac41c2c2864629a24f0f1982bda9e3"}},"7a5551339b9c4b6685cabe1f4bb8d761":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac0034454103441698245a85b0d39681","placeholder":"​","style":"IPY_MODEL_fcc1a8ca0e3147f191eb5e16a0f40e0a","value":"model.safetensors: 100%"}},"52a6d6de75b14ee794da273704e0201b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab28dac94f8243688c6d4cfbfb9032fa","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_054238d8d6934627be20ffce1477607d","value":440449768}},"6b09ed1c3d0444af98f856d530dd49da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e28513341fc645fbb78e91413b6baccb","placeholder":"​","style":"IPY_MODEL_3dcf8eafd0b046dc8bf1855cd6e1d141","value":" 440M/440M [00:02&lt;00:00, 151MB/s]"}},"80ac41c2c2864629a24f0f1982bda9e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac0034454103441698245a85b0d39681":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcc1a8ca0e3147f191eb5e16a0f40e0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab28dac94f8243688c6d4cfbfb9032fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"054238d8d6934627be20ffce1477607d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e28513341fc645fbb78e91413b6baccb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dcf8eafd0b046dc8bf1855cd6e1d141":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## Fine-tune BERT to make predictions based on specific train and validation sets"],"metadata":{"id":"3WheuS8MOup6"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"RbyIsnVMNuBQ","colab":{"base_uri":"https://localhost:8080/","height":503,"referenced_widgets":["44011120ae5442d9a43689af71b87f9e","e49dadef281941488c426e5c4626ed13","eb2a8b544d5c41eea2db1b2a56e88d33","b6af843580634335bf0ebdfc6a9baf62","6c785cef0fb249a69ea6b30815b23a55","b9e4d38e7bf6427893a606ea64d6295b","66dbcfde174149268bf7c8a3124a87e3","0c36128f963d4e6e9ec05fa77c6193d5","8204ff0390284060ad7892d92f56565a","a6a76cdca4a544d5919f5bba09aa6345","ad97067e92474e56abd5708b521d6d88","00110d9a1a704460a1a9fde626b89275","bb75fc3d2a6a4cbab0faa6f934b74379","8261f7d145e34a6aaffc2eb1ba083afc","6e2b00787160478d868e32c4928aba1b","c77bfcd35a6f422482eba59bb7e8273c","a711e963016a46c2b2b62fd19a13dc30","338c81578b6c496d940d9e61c75bdbe0","0e79496069854401ba5c879b2ab52388","a399a7f948ed47d6ae2b68d593f2810d","4d55bdb4b5e54cba97d6946c80b2c7f7","9587349a72c64e4189308080881d6e1b","518e0780b65b4f6696d060aae15f78b3","31dd4d411d994276b579792c3cbd7028","9fa4a30645b84183a5d0c81030e9b437","5efe421d3b33487d91b19dcc474c09fc","1496a4e2d81e462d8a6ebc6eea4b34b1","4e818d0c6415424facd7f99772c5e9b2","d292bef3784849a797b3a158549032c3","0af1c62eea854dcd95e74ac124b43a32","cfd2dd273a564c70b5a228b955d9add3","40f2646b2b074bd2821492ecbb9a4115","1662d3e065b44a56a8f29cd615b9e419","064fa52e7d98449996f64c79398ae065","bb2b4d56562b45dcb6c5e31072b6dbe7","afff58cb478b4a93a56d840a5ad95481","c25e27d1d15e49cc8a109462034547a6","255b3ad2d71948fb97c071dfcc72750a","e5d34f2d640f48fc8848d63821d11a18","2ed8ab2aff414b41b3bd75e8cbde1850","4ae39ec1fa014d16b45648124ba8ea47","5f3408a63bd54e72be913566a1458d8a","86c526b18dc94b62a1fed8bbf0ef828b","60124a541126438ba65fe80275037ba9","f7c2756e2b6746cf95f2278a7b982681","7a5551339b9c4b6685cabe1f4bb8d761","52a6d6de75b14ee794da273704e0201b","6b09ed1c3d0444af98f856d530dd49da","80ac41c2c2864629a24f0f1982bda9e3","ac0034454103441698245a85b0d39681","fcc1a8ca0e3147f191eb5e16a0f40e0a","ab28dac94f8243688c6d4cfbfb9032fa","054238d8d6934627be20ffce1477607d","e28513341fc645fbb78e91413b6baccb","3dcf8eafd0b046dc8bf1855cd6e1d141"]},"outputId":"4719e9cb-eaff-4022-b7d5-762fa0397a5d","executionInfo":{"status":"ok","timestamp":1729917589046,"user_tz":-180,"elapsed":900694,"user":{"displayName":"Konstantinos Roumeliotis","userId":"17264923090131634662"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44011120ae5442d9a43689af71b87f9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00110d9a1a704460a1a9fde626b89275"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"518e0780b65b4f6696d060aae15f78b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"064fa52e7d98449996f64c79398ae065"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7c2756e2b6746cf95f2278a7b982681"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1/3: 100%|██████████| 534/534 [03:51<00:00,  2.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3 - Training Loss: 0.1531 - Validation Loss: 0.1000 - Validation Accuracy: 0.9575\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3: 100%|██████████| 534/534 [03:57<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3 - Training Loss: 0.0396 - Validation Loss: 0.0470 - Validation Accuracy: 0.9875\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3: 100%|██████████| 534/534 [03:57<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/3 - Training Loss: 0.0294 - Validation Loss: 0.0386 - Validation Accuracy: 0.9900\n","Training time: 877.48 seconds\n"]}],"source":["import os\n","import pandas as pd\n","from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, AdamW\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import accuracy_score\n","import torch\n","import time\n","from tqdm import tqdm\n","from google.colab import drive\n","\n","class SequenceClassificationDataset(Dataset): # Handle the input data and labels for PyTorch's DataLoader\n","    def __init__(self, inputs, labels):\n","        self.inputs = inputs\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.inputs['input_ids']) # Return the total number of samples in the dataset\n","\n","    def __getitem__(self, idx):\n","        # Retrieve the input_ids, attention_mask, and label corresponding to the index\n","        input_ids = self.inputs['input_ids'][idx]\n","        attention_mask = self.inputs['attention_mask'][idx]\n","        label = self.labels[idx]\n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","class BertFineTuning:\n","    def __init__(self, dataset_path, train_file, validation_file, feature_col, label_col, model_name, batch_size, learning_rate, num_epochs, max_len, optimizer=None, device='cpu'):\n","        self.dataset_path = dataset_path\n","        self.train_file = train_file\n","        self.validation_file = validation_file\n","        self.feature_col = feature_col\n","        self.label_col = label_col\n","        self.model_name = model_name\n","        self.batch_size = batch_size\n","        self.learning_rate = learning_rate\n","        self.num_epochs = num_epochs\n","        self.max_len = max_len\n","        self.optimizer = optimizer\n","        self.device = torch.device(device)  # Convert device argument to torch.device\n","        drive.mount('/content/gdrive') # Mount Google Drive\n","\n","        # Load tokenizer\n","        self.tokenizer = BertTokenizer.from_pretrained(self.model_name, max_len=self.max_len)\n","\n","        # Load datasets\n","        self.train_df = pd.read_csv(os.path.join(self.dataset_path, self.train_file))\n","        self.validation_df = pd.read_csv(os.path.join(self.dataset_path, self.validation_file))\n","\n","        # Label Transformation Guide:\n","        # ---------------------------\n","        # Many machine learning models, including those in PyTorch and Hugging Face Transformers, use zero-based indexing for classification tasks.\n","        # [1] For conventional labels [1, 2, 3, 4, 5], transform them to zero-based indexing [0, 1, 2, 3, 4] by subtracting 1.\n","        #     This allows training the model using zero-based labels and adjusting predictions accordingly.\n","        # [2] For zero-based labels (e.g., [0, 1, 2]), skip the label transformation step.\n","        #     Ensure to adjust the prediction phase accordingly, removing any +1 offset on predicted labels.\n","        # [3] In general, preprocess your dataset to transform labels into a conventional format (e.g., [0, 1, 2]) before model training.\n","\n","        # Specific Label Transformations:\n","        # -------------------------------\n","        # [1] Convert labels [1, 2, 3, 4, 5] to [0, 1, 2, 3, 4] by subtracting 1. Example: [1 → 0, 2 → 1, 3 → 2, 4 → 3, 5 → 4]\n","        # [2] Convert labels [-1, 0, 1] to [0, 1, 2] by adding 1. Example: [-1 → 0, 0 → 1, 1 → 2]\n","        # [3] Convert string labels to numerical format before model training. Implement a mapping strategy to translate string labels into numerical representations.\n","\n","        # Note on Prediction Phase:\n","        # --------------------------\n","        # [*] Ensure to reverse label transformations during prediction to map model outputs back to the original label space.\n","        #     For example, if using zero-based labels during training, add 1 to predicted indices to align with the original labels.\n","\n","        # self.train_df[self.label_col] = self.train_df[self.label_col] - 1\n","        # self.validation_df[self.label_col] = self.validation_df[self.label_col] - 1\n","\n","        # Calculate number of unique labels\n","        self.num_labels = len(self.train_df[self.label_col].unique())\n","\n","        # Tokenize datasets\n","        self.tokenized_train = self.tokenize_dataset(self.train_df, self.feature_col, self.label_col)\n","        self.tokenized_validation = self.tokenize_dataset(self.validation_df, self.feature_col, self.label_col)\n","\n","        # Model configuration\n","        self.model_config = BertConfig.from_pretrained(self.model_name, num_labels=self.num_labels)\n","        self.model = BertForSequenceClassification.from_pretrained(self.model_name, config=self.model_config)\n","        self.model.to(self.device)\n","\n","        # Optimizer\n","        if self.optimizer is None:\n","            raise ValueError(\"Please provide an optimizer instance.\")\n","\n","        if self.optimizer == 'Adam':\n","            self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n","        elif self.optimizer == 'AdamW':\n","            self.optimizer = AdamW(self.model.parameters(), lr=self.learning_rate)\n","\n","        # DataLoaders\n","        self.train_dataloader = self.create_dataloader(self.tokenized_train)\n","        self.validation_dataloader = self.create_dataloader(self.tokenized_validation, shuffle=False)\n","\n","    def tokenize_dataset(self, df, feature_col, label_col):\n","        return self.tokenizer(list(df[feature_col]),\n","                              padding=True,\n","                              truncation=True,\n","                              return_tensors='pt'), list(df[label_col])\n","\n","    def create_dataloader(self, tokenized_dataset, shuffle=True):\n","        dataset = SequenceClassificationDataset(tokenized_dataset[0], tokenized_dataset[1])\n","        return DataLoader(dataset, batch_size=self.batch_size, shuffle=shuffle)\n","\n","    def evaluate_model(self, dataloader):\n","        self.model.eval() # Set the model to evaluation mode\n","        # Initialize lists to store true labels and predictions\n","        all_labels = []\n","        all_predictions = []\n","\n","        with torch.no_grad():\n","            for batch in dataloader: # Iterate over batches in the data loader\n","                inputs = {key: value.to(self.device) for key, value in batch.items()} # Move inputs to the appropriate device (CPU or GPU)\n","                labels = inputs[\"labels\"] # Extract labels from inputs\n","                outputs = self.model(**inputs) # Forward pass through the model\n","                logits = outputs.logits # Get logits from the model output\n","\n","                _, predicted = torch.max(logits, 1) # Compute predicted labels\n","                # Convert labels and predictions to numpy arrays\n","                all_labels.extend(labels.cpu().numpy())\n","                all_predictions.extend(predicted.cpu().numpy())\n","\n","        accuracy = accuracy_score(all_labels, all_predictions) # Calculate accuracy\n","        return accuracy\n","\n","    def train(self):\n","        for epoch in range(self.num_epochs): # Iterate over the num_epochs of epochs\n","            self.model.train() # Set the model to training mode\n","            train_losses = [] # List to store training losses for each batch\n","\n","            # Iterate over batches in the training data loader, displaying progress using tqdm\n","            for batch in tqdm(self.train_dataloader, desc=f'Epoch {epoch + 1}/{self.num_epochs}'):\n","                inputs = {key: value.to(self.device) for key, value in batch.items()} # Move inputs to the appropriate device (CPU or GPU)\n","                outputs = self.model(**inputs) # Forward pass through the model\n","                loss = outputs.loss # Retrieve the loss from the model output\n","                train_losses.append(loss.item()) # Append the loss value to the list of training losses\n","\n","                self.optimizer.zero_grad() # Zero the gradients\n","                loss.backward() # Backpropagate the gradients\n","                self.optimizer.step() # Update the model parameters\n","\n","            # Validation\n","            validation_losses = [] # Initialize an empty list to store validation losses\n","            validation_accuracy = self.evaluate_model(self.validation_dataloader) # Evaluate model performance on the validation data loader\n","\n","            for batch in self.validation_dataloader:\n","              inputs = {key: value.to(self.device) for key, value in batch.items()} # Move inputs to the appropriate device (CPU or GPU)\n","              outputs = self.model(**inputs) # Forward pass through the model\n","              loss = outputs.loss # Retrieve the loss from the model output\n","              validation_losses.append(loss.item()) # Append the loss value to the list of validation losses\n","\n","            print(f'Epoch {epoch + 1}/{self.num_epochs} - Training Loss: {sum(train_losses) / len(train_losses):.4f} - Validation Loss: {sum(validation_losses) / len(validation_losses):.4f} - Validation Accuracy: {validation_accuracy:.4f}')\n","\n","            # print(f'Epoch {epoch + 1}/{self.num_epochs} - Training Loss: {sum(train_losses) / len(train_losses):.4f} - Validation Accuracy: {validation_accuracy:.4f}')\n","\n","    def save_model(self, directory):\n","        self.model.save_pretrained(directory)\n","        self.tokenizer.save_pretrained(directory)\n","\n","# Usage\n","start_time = time.time()\n","model = 'bert'\n","model_name = 'bert-base-uncased'\n","\n","## Hyperparameters\n","learning_rate = 2e-5\n","num_epochs = 3\n","batch_size = 6\n","\n","# Maximum sequence length for padding and truncation\n","# ---------------------------------------------------\n","# The maximum sequence length limit for BERT/RoBERTa is 512 tokens (approximately 512x5=2,560 characters).\n","# If an input exceeds 512 tokens, the text is truncated to meet this maximum length.\n","# If an input is shorter than 512 tokens, the text is padded to achieve the maximum length.\n","# However, techniques such as chunking or hierarchical processing can handle longer texts by segmenting\n","#   the input text into smaller segments, processing each segment separately, and then combining the results.\n","# Nevertheless, these techniques can introduce complexities and potential drawbacks.\n","max_len = 512\n","\n","optimizer = 'Adam' # Adam or AdamW\n","device = 'cuda' if torch.cuda.is_available() else 'cpu' # or device = 'cpu'\n","\n","## Paths and filenames\n","absolute_path = \"/content/gdrive/My Drive/Projects/SpamNews/\"\n","dataset_path = absolute_path + \"Datasets/\"\n","train_file = 'train_set.csv'\n","validation_file = 'validation_set.csv'\n","feature_col = 'Text'\n","label_col = 'Label'\n","trained_model = model + '_optimizer_' + optimizer + '_lr_' + str(learning_rate) + '_epochs_' + str(num_epochs) + '_bs_' + str(batch_size) + '_maxlen_' + str(max_len)\n","\n","# Fine-Tuning Phase\n","classifier = BertFineTuning(dataset_path, train_file, validation_file, feature_col, label_col, model_name, batch_size, learning_rate, num_epochs, max_len, optimizer, device)\n","classifier.train()\n","classifier.save_model(absolute_path + 'TrainedModels/' + trained_model)\n","print(\"Training time: {:.2f} seconds\".format(time.time() - start_time))"]},{"cell_type":"markdown","source":["## Use the Fine-tuned BERT model to make predictions for a specific test set"],"metadata":{"id":"T8BihUZTO2L9"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from tqdm import tqdm\n","from google.colab import drive\n","\n","class BertPredictions:\n","    def __init__(self, model_path, device, max_len):\n","        drive.mount('/content/gdrive') # Mount Google Drive\n","        self.model_path = model_path\n","        self.max_len = max_len\n","        self.device = torch.device(device)  # Convert device argument to torch.device\n","        self.model, self.tokenizer = self.load_fine_tuned_bert_model()\n","\n","    def load_fine_tuned_bert_model(self):\n","        model = BertForSequenceClassification.from_pretrained(self.model_path) # Load the fine-tuned BERT model\n","        tokenizer = BertTokenizer.from_pretrained(self.model_path) # Load the tokenizer\n","        model.to(self.device) # Move the model to the specified device\n","        return model, tokenizer\n","\n","    def predict(self, input):\n","        tokens = self.tokenizer.tokenize(self.tokenizer.decode(self.tokenizer.encode(input))) # Tokenize the input using the loaded tokenizer\n","\n","        # Truncate the tokens if the length exceeds max_len - 2\n","        if len(tokens) > self.max_len - 2:\n","            tokens = tokens[:self.max_len - 2]\n","\n","        # Encode the tokens and convert them to PyTorch tensor\n","        input_ids = self.tokenizer.encode(tokens, return_tensors=\"pt\").to(self.device)\n","\n","        with torch.no_grad():\n","            self.model.eval() # Set the model to evaluation mode\n","            logits = self.model(input_ids)[0] # Perform forward pass through the model\n","            predictions = torch.argmax(logits, dim=1).item() # Predict the label by selecting the index with the highest logit value\n","\n","        # return predictions + 1 # For non zero-based labels subtract while training and +1 during prediction\n","        return predictions\n","\n","    def predict_and_save(self, dataset_path, test_file, feature_col, prediction_col):\n","        # Load the test dataset\n","        test_df = pd.read_csv(os.path.join(dataset_path, test_file))\n","\n","        # Backup the original file by renaming it\n","        os.rename(os.path.join(dataset_path, test_file), os.path.join(dataset_path, 'test_set_original.csv'))\n","\n","        # Iterate through each row in the DataFrame\n","        for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n","            content = row[feature_col]\n","\n","            # Process the content and predict the label\n","            predicted_rating = self.predict(content)\n","\n","            # Update the prediction_col column\n","            test_df.at[index, prediction_col] = predicted_rating\n","\n","        # Save results to CSV\n","        test_df.to_csv(os.path.join(dataset_path, test_file), index=False)\n","\n","# Usage\n","max_len = 512\n","\n","str_params = 'bert_optimizer_Adam_lr_2e-05_epochs_3_bs_6_maxlen_512'\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Determine device\n","optimizer = \"Adam\"  # Set the correct optimizer\n","\n","## Paths and filenames\n","path = \"/content/gdrive/My Drive/Projects/SpamNews/\"\n","dataset_path = path + \"Datasets/\"\n","test_file = \"test_set.csv\"\n","trained_model = path + 'TrainedModels/' + str_params  # The fine-tuned model\n","feature_col = 'Text'\n","prediction_col = str_params + '_prediction'\n","\n","# Instantiate the BertPredictions class\n","prediction = BertPredictions(trained_model, device, max_len)\n","\n","# Run prediction and save results to CSV\n","prediction.predict_and_save(dataset_path, test_file, feature_col, prediction_col)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cf0W9cXnOpdM","outputId":"63d46dbb-145b-4db2-80db-5c0785f4eb67","executionInfo":{"status":"ok","timestamp":1729917945893,"user_tz":-180,"elapsed":42230,"user":{"displayName":"Konstantinos Roumeliotis","userId":"17264923090131634662"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [00:34<00:00, 29.00it/s]\n"]}]}]}